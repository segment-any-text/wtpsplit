{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(\"python_lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm\n",
    "import nnsplit\n",
    "from nnsplit import train, utils, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = Path(\"cache\")\n",
    "cache_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f65995ecb0014b1aa685963ac7bc1cd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3000000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "paragraphs = train.xml_to_paragraphs(\"train_data/dewiki-20180920-corpus.xml\", max_n_paragraphs=3_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nnsplit.tokenizer.SoMaJoTokenizer(\"de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff8384c996ac41449c9d7c0779a268aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3000000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(cache_dir / \"de_data\" / \"tokenized_paragraphs.pkl\", \"wb\") as f:\n",
    "    for x in tokenizer.split(paragraphs, verbose=True):\n",
    "        f.write(pickle.dumps(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = train.xml_to_paragraphs(\"train_data/enwiki-20181001-corpus.xml\", max_n_paragraphs=3_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nnsplit.tokenizer.SoMaJoTokenizer(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(cache_dir / \"en_data\" / \"tokenized_paragraphs.pkl\", \"wb\") as f:\n",
    "    for x in tokenizer.split(paragraphs, verbose=True):\n",
    "        f.write(pickle.dumps(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model (german)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fc7634496c64560914446817789d120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faulty paragraph:\n",
      "[[Token(text='.', whitespace='')], [Token(text='GLOBAL', whitespace=' '), Token(text='_set_float', whitespace=''), Token(text='Extend', whitespace=''), Token(text=';', whitespace=' '), Token(text=';', whitespace=' '), Token(text='Sprunglabel', whitespace=' '), Token(text='global', whitespace=' '), Token(text='sichtbar', whitespace=' '), Token(text='_set_float', whitespace=''), Token(text='Extend', whitespace=''), Token(text=':', whitespace=' '), Token(text=';', whitespace=' '), Token(text='Sprunglabel', whitespace=' '), Token(text='angeben', whitespace=''), Token(text=',', whitespace=' '), Token(text='das', whitespace=' '), Token(text='ist', whitespace=' '), Token(text='der', whitespace=' '), Token(text='Name', whitespace=' '), Token(text='des', whitespace=' '), Token(text='Unterprogramms', whitespace=''), Token(text=',', whitespace=' '), Token(text=';', whitespace=' '), Token(text='aus', whitespace=' '), Token(text='C', whitespace=' '), Token(text='ohne', whitespace=' '), Token(text='Unterstrich', whitespace=' '), Token(text='anzugeben', whitespace=''), Token(text='.', whitespace=' ')], [Token(text='I4', whitespace=' '), Token(text='=', whitespace=' '), Token(text='R4', whitespace=''), Token(text=';', whitespace=' '), Token(text=';', whitespace=' '), Token(text='Im', whitespace=' '), Token(text='Register', whitespace=' '), Token(text='R4', whitespace=' '), Token(text='wird', whitespace=' '), Token(text='der', whitespace=' '), Token(text='erste', whitespace=' '), Token(text='Parameter', whitespace=' '), Token(text='_float', whitespace=''), Token(text='Extend', whitespace=''), Token(text='*', whitespace=' '), Token(text='dst', whitespace=' '), Token(text='übergeben', whitespace=''), Token(text='.', whitespace=' '), Token(text=';', whitespace=' '), Token(text='Da', whitespace=' '), Token(text='es', whitespace=' '), Token(text='eine', whitespace=' '), Token(text='Adresse', whitespace=' '), Token(text='ist', whitespace=''), Token(text=',', whitespace=' '), Token(text='wird', whitespace=' '), Token(text='diese', whitespace=' '), Token(text='in', whitespace=' '), Token(text='das', whitespace=' '), Token(text='Adressregister', whitespace=' '), Token(text='I4', whitespace=' '), Token(text='umgeladen', whitespace=''), Token(text='.', whitespace=' ')], [Token(text='PX', whitespace=' '), Token(text='=', whitespace=' '), Token(text='F8', whitespace=''), Token(text=';', whitespace=' '), Token(text=';', whitespace=' '), Token(text='Der', whitespace=' '), Token(text='zweite', whitespace=' '), Token(text='Parameter', whitespace=' '), Token(text='float', whitespace=' '), Token(text='nVal', whitespace=' '), Token(text='wird', whitespace=' '), Token(text='aus', whitespace=' '), Token(text='F8', whitespace=' '), Token(text='in', whitespace=' '), Token(text='das', whitespace=' '), Token(text='Register', whitespace=' '), Token(text='PX', whitespace=' '), Token(text='geladen', whitespace=''), Token(text='.', whitespace=' '), Token(text='dm', whitespace=''), Token(text='(', whitespace=''), Token(text='0', whitespace=''), Token(text=',', whitespace=''), Token(text='I4', whitespace=''), Token(text=')', whitespace=' '), Token(text='=', whitespace=' '), Token(text='PX1', whitespace=''), Token(text=';', whitespace=' '), Token(text=';', whitespace=' '), Token(text='Ein', whitespace=' '), Token(text='Teil', whitespace=' '), Token(text='des', whitespace=' '), Token(text='Inhaltes', whitespace=' '), Token(text='von', whitespace=' '), Token(text='PX', whitespace=''), Token(text=',', whitespace=' '), Token(text='in', whitespace=' '), Token(text='PX1', whitespace=' '), Token(text='sichtbar', whitespace=''), Token(text=',', whitespace=' '), Token(text='wird', whitespace=' '), Token(text='auf', whitespace=' '), Token(text=';', whitespace=' '), Token(text='der', whitespace=' '), Token(text='Adresse', whitespace=' '), Token(text='gespeichert', whitespace=''), Token(text=',', whitespace=' '), Token(text='die', whitespace=' '), Token(text='von', whitespace=' '), Token(text='I4', whitespace=' '), Token(text='gezeigert', whitespace=' '), Token(text='wird', whitespace=''), Token(text='.', whitespace=' '), Token(text='dm', whitespace=''), Token(text='(', whitespace=''), Token(text='1', whitespace=''), Token(text=',', whitespace=''), Token(text='I4', whitespace=''), Token(text=')', whitespace=' '), Token(text='=', whitespace=' '), Token(text='PX2', whitespace=''), Token(text=';', whitespace=' '), Token(text=';', whitespace=' '), Token(text='Speicherung', whitespace=' '), Token(text='des', whitespace=' '), Token(text='zweiten', whitespace=' '), Token(text='Teils', whitespace=' '), Token(text='auf', whitespace=' '), Token(text='der', whitespace=' '), Token(text='Folgeadresse', whitespace=' '), Token(text='!', whitespace=' ')], [Token(text='FUNCTION', whitespace=' '), Token(text='EPILOGUE', whitespace=''), Token(text=':', whitespace=' '), Token(text=';', whitespace=' '), Token(text='Standard-Abschluss', whitespace=' '), Token(text='des', whitespace=' '), Token(text='Unterprogramms', whitespace=''), Token(text=':', whitespace=' '), Token(text='i12', whitespace=' '), Token(text='=', whitespace=' '), Token(text='dm', whitespace=''), Token(text='(', whitespace=''), Token(text='-1', whitespace=''), Token(text=',', whitespace=''), Token(text='i6', whitespace=''), Token(text=')', whitespace=''), Token(text=';', whitespace=' '), Token(text=';', whitespace=' '), Token(text='Das', whitespace=' '), Token(text='Adressregister', whitespace=' '), Token(text='i12', whitespace=' '), Token(text='wird', whitespace=' '), Token(text='aus', whitespace=' '), Token(text='einer', whitespace=' '), Token(text='Adresse', whitespace=' '), Token(text='relativ', whitespace=' '), Token(text='zum', whitespace=' '), Token(text='Basepointer', whitespace=' '), Token(text=';(', whitespace=''), Token(text='hier', whitespace=' '), Token(text='i6', whitespace=''), Token(text=')', whitespace=' '), Token(text='geladen', whitespace=''), Token(text='.', whitespace=' ')], [Token(text='Das', whitespace=' '), Token(text='ist', whitespace=' '), Token(text='die', whitespace=' '), Token(text='Rücksprungadresse', whitespace=''), Token(text='.', whitespace=' '), Token(text='jump', whitespace=' '), Token(text='(', whitespace=''), Token(text='m14', whitespace=''), Token(text=',', whitespace=''), Token(text='i12', whitespace=''), Token(text=')', whitespace=' '), Token(text='(', whitespace=''), Token(text='DB', whitespace=''), Token(text=')', whitespace=' '), Token(text=';', whitespace=' '), Token(text='Das', whitespace=' '), Token(text='ist', whitespace=' '), Token(text='der', whitespace=' '), Token(text='Rücksprung', whitespace=' '), Token(text='unter', whitespace=' '), Token(text='Nutzung', whitespace=' '), Token(text='des', whitespace=' '), Token(text='Registers', whitespace=' '), Token(text='i12', whitespace=''), Token(text='.', whitespace=' ')], [Token(text='F0', whitespace=' '), Token(text='=', whitespace=' '), Token(text='F8', whitespace=''), Token(text=';', whitespace=' '), Token(text=';', whitespace=' '), Token(text='nach', whitespace=' '), Token(text='dem', whitespace=' '), Token(text='Rücksprung', whitespace=' '), Token(text='werden', whitespace=' '), Token(text='die', whitespace=' '), Token(text='noch', whitespace=' '), Token(text='im', whitespace=' '), Token(text='cashe', whitespace=' '), Token(text='stehenden', whitespace=' '), Token(text='Befehl', whitespace=' '), Token(text='verarbeitet', whitespace=''), Token(text=',', whitespace=' '), Token(text=';', whitespace=' '), Token(text='hier', whitespace=' '), Token(text='wird', whitespace=' '), Token(text='der', whitespace=' '), Token(text='Wert', whitespace=' '), Token(text='in', whitespace=' '), Token(text='F8', whitespace=' '), Token(text='nach', whitespace=' '), Token(text='dem', whitespace=' '), Token(text='Register', whitespace=' '), Token(text='R0', whitespace=' '), Token(text='geladen', whitespace=''), Token(text=',', whitespace=' '), Token(text='für', whitespace=' '), Token(text='return', whitespace=''), Token(text='.', whitespace=' ')], [Token(text='RFRAME', whitespace=''), Token(text=';', whitespace=' '), Token(text=';', whitespace=' '), Token(text='dieser', whitespace=' '), Token(text='Befehl', whitespace=' '), Token(text='korrigiert', whitespace=' '), Token(text='den', whitespace=' '), Token(text='Basepointer', whitespace=' '), Token(text='i6', whitespace=' '), Token(text='und', whitespace=' '), Token(text='Stackpointer', whitespace=' '), Token(text='i7', whitespace=''), Token(text='.', whitespace='')]]\n"
     ]
    }
   ],
   "source": [
    "sentences, labels = train.prepare_tokenized_paragraphs(cache_dir / \"de_data\" / \"tokenized_paragraphs.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(sentences, labels, test_size=0.1, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.031820</td>\n",
       "      <td>0.031392</td>\n",
       "      <td>02:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "de_model = train.train(x_train, y_train, x_valid, y_valid, n_epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(de_model, cache_dir / \"de_data\" / \"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bminixhofer/miniconda3/lib/python3.7/site-packages/tensorflowjs/converters/keras_h5_conversion.py:122: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  return h5py.File(h5file)\n"
     ]
    }
   ],
   "source": [
    "utils.store_model(de_model, \"data/de\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_model = torch.load(cache_dir / \"de_data\" / \"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c62e11540ce94ab49baccd9794781cda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1172.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target: Tokenize \n",
      "\n",
      "F1: 0.9976920067068228\n",
      "Precision: 0.9979479501565672\n",
      "Recall: 0.997436194506916\n",
      "\n",
      "\n",
      "\n",
      "Target: Sentencize \n",
      "\n",
      "F1: 0.9584361802317378\n",
      "Precision: 0.9373894356306759\n",
      "Recall: 0.9804497366219669\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.evaluate(de_model.cuda().half(), x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_model = torch.quantization.quantize_dynamic(de_model.float().cpu(), {nn.LSTM, nn.Linear}, dtype=torch.qint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e110baec60f442c5afd934a8d22af664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=977.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target: Tokenize \n",
      "\n",
      "F1: 0.9985806618134485\n",
      "Precision: 0.9977847594261771\n",
      "Recall: 0.9993778349483429\n",
      "\n",
      "\n",
      "\n",
      "Target: Sentencize \n",
      "\n",
      "F1: 0.9581120292762628\n",
      "Precision: 0.9363237215520647\n",
      "Recall: 0.9809385261100492\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.evaluate(quantized_model, x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model (english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "943d2f79542f4045930582d9182c0eb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentences, labels = train.prepare_tokenized_paragraphs(cache_dir / \"en_data\" / \"tokenized_paragraphs.pkl\", \"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(sentences, labels, test_size=0.1, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.040443</td>\n",
       "      <td>0.038892</td>\n",
       "      <td>20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.032624</td>\n",
       "      <td>0.031846</td>\n",
       "      <td>20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.030703</td>\n",
       "      <td>0.030959</td>\n",
       "      <td>20:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.030231</td>\n",
       "      <td>0.030827</td>\n",
       "      <td>20:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.029231</td>\n",
       "      <td>0.030218</td>\n",
       "      <td>20:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.028824</td>\n",
       "      <td>0.029291</td>\n",
       "      <td>20:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.029228</td>\n",
       "      <td>0.028684</td>\n",
       "      <td>20:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.028699</td>\n",
       "      <td>0.027927</td>\n",
       "      <td>20:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.026893</td>\n",
       "      <td>0.027063</td>\n",
       "      <td>20:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.027493</td>\n",
       "      <td>0.026111</td>\n",
       "      <td>20:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.024701</td>\n",
       "      <td>0.025307</td>\n",
       "      <td>20:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.024740</td>\n",
       "      <td>0.024440</td>\n",
       "      <td>20:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.023115</td>\n",
       "      <td>0.023700</td>\n",
       "      <td>20:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.022261</td>\n",
       "      <td>0.023100</td>\n",
       "      <td>20:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.022435</td>\n",
       "      <td>0.022958</td>\n",
       "      <td>20:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "en_model = train.train(x_train, y_train, x_valid, y_valid, n_epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(en_model, cache_dir / \"en_data\" / \"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bminixhofer/miniconda3/lib/python3.7/site-packages/tensorflowjs/converters/keras_h5_conversion.py:122: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  return h5py.File(h5file)\n"
     ]
    }
   ],
   "source": [
    "utils.store_model(en_model, \"data/en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_model = torch.load(cache_dir / \"en_data\" / \"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dac7985ce62a4873b338c523f3132751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1172.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target: Tokenize \n",
      "\n",
      "F1: 0.9978134907239008\n",
      "Precision: 0.9981640633909579\n",
      "Recall: 0.9974631642248826\n",
      "\n",
      "\n",
      "\n",
      "Target: Sentencize \n",
      "\n",
      "F1: 0.9413314661724994\n",
      "Precision: 0.9120622157846446\n",
      "Recall: 0.9725415771060246\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.evaluate(en_model.cuda().half(), x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_model = torch.quantization.quantize_dynamic(en_model.float().cpu(), {nn.LSTM, nn.Linear}, dtype=torch.qint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e110baec60f442c5afd934a8d22af664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=977.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target: Tokenize \n",
      "\n",
      "F1: 0.9985806618134485\n",
      "Precision: 0.9977847594261771\n",
      "Recall: 0.9993778349483429\n",
      "\n",
      "\n",
      "\n",
      "Target: Sentencize \n",
      "\n",
      "F1: 0.9581120292762628\n",
      "Precision: 0.9363237215520647\n",
      "Recall: 0.9809385261100492\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.evaluate(quantized_model, x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnsplit import NNSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = NNSplit(utils.load_model(\"data/de\").float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[Token(text='Das', whitespace=' '),\n",
       "   Token(text='ist', whitespace=' '),\n",
       "   Token(text='ein', whitespace=' '),\n",
       "   Token(text='Test', whitespace=' ')],\n",
       "  [Token(text='Das', whitespace=' '),\n",
       "   Token(text='ist', whitespace=' '),\n",
       "   Token(text='noch', whitespace=' '),\n",
       "   Token(text='ein', whitespace=' '),\n",
       "   Token(text='Test', whitespace=''),\n",
       "   Token(text='.', whitespace='')]]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitter.split([\"Das ist ein Test Das ist noch ein Test.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = NNSplit(utils.load_model(\"data/en\").float())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
